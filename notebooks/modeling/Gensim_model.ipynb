{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19567a29-4abf-45a1-bd6a-23799db1209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fc7c87-dcc0-4f5b-94cf-27dda8144e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('arabic_gensim_reviews.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab7e36a-e745-494e-8a2b-ec8f39690c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 500\n",
      "Rows after filtering: 489\n",
      "Rows dropped: 11\n"
     ]
    }
   ],
   "source": [
    "MinimumArabicPercentage = 0.6\n",
    "\n",
    "original_count = len(df)\n",
    "\n",
    "df = df[df['arabic_ratio'] >= MinimumArabicPercentage]\n",
    "\n",
    "filtered_count = len(df)\n",
    "\n",
    "print(f\"Original rows: {original_count:,}\")\n",
    "print(f\"Rows after filtering: {filtered_count:,}\")\n",
    "print(f\"Rows dropped: {original_count - filtered_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cc1eb3-c813-4031-ad04-04ee35dbb60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA INSPECTION ===\n",
      "Dataset shape: (489, 8)\n",
      "\n",
      "First few rows of each column:\n",
      "\n",
      "text_stem:\n",
      "نعل ريح ردي هذه نعل كثر فهي دفي ريح سعر عقل لجد ريع زوج ونا علي حد سوا لدي زوج ونح نحب\n",
      "Type: <class 'str'>\n",
      "Has NaN: 0\n",
      "\n",
      "char_3grams:\n",
      "الن لنع نعا عال ال  ل ا  ال الم لمر مري ريح يحه حه  ه     ا  ار ارت رتد تدي دي  ي ه  هذ هذه ذه  ه ا \n",
      "Type: <class 'str'>\n",
      "Has NaN: 0\n",
      "\n",
      "char_4grams:\n",
      "النع لنعا نعال عال  ال ا ل ال  الم المر لمري مريح ريحه يحه  حه   ه  ا   ار  ارت ارتد رتدي تدي  دي ه \n",
      "Type: <class 'str'>\n",
      "Has NaN: 0\n",
      "\n",
      "pos_tags:\n",
      "النعال_NOUN|المريحة_ADJ|:_PUNCT|أرتدي_VERB|هذه_DET|النعال_NOUN|كثيرً_ADJ|ا_PART|!_PUNCT|ف_CCONJ|هي_P\n",
      "Type: <class 'str'>\n",
      "Has NaN: 0\n",
      "\n",
      "average_embedding:\n",
      "Type: <class 'str'>\n",
      "Sample value: 0.114897 -0.199195 0.210921 -0.155489 -0.186678 -0.280694 -0.054041 0.727783 0.042974 0.248400 0.046069 -0.282640 -0.191562 0.332183 0.084809 0.477737 -0.150289 -0.457169 -0.307497 -0.135764 0.193260 0.159790 0.119106 0.358983 -0.417942 0.344787 -0.113754 0.050885 0.017103 -0.000881 -0.168916 0.328670 0.095492 0.056142 -0.074894 0.152642 -0.153118 -0.338182 0.205369 -0.391910 0.034261 0.318318 0.056301 0.105539 0.065178 0.390943 0.002248 0.082625 0.194763 0.238329 -0.084997 -0.221566 -0.390929 -0.355241 0.052537 0.027094 0.474081 0.014063 0.449739 0.107685 0.665018 0.171321 0.196080 0.020115 -0.071704 0.167228 0.280769 -0.061603 0.073504 -0.079971 -0.095593 0.156730 0.399963 0.053474 0.160289 0.340290 0.208787 -0.053515 -0.389570 0.059489 -0.132425 0.059467 -0.526981 0.076510 -0.298492 -0.007443 -0.697283 -0.293490 -0.108231 -0.321003 0.218425 -0.177363 0.258567 0.294573 -0.103613 0.473612 0.083573 0.096396 0.104332 -0.128241\n",
      "Has NaN: 0\n",
      "\n",
      "=== EMPTY STRING CHECK ===\n",
      "text_stem - Empty strings: 0\n",
      "char_3grams - Empty strings: 0\n",
      "char_4grams - Empty strings: 0\n",
      "pos_tags - Empty strings: 0\n",
      "\n",
      "=== AVERAGE EMBEDDING CHECK ===\n",
      "average_embedding - NaN values: 0\n",
      "average_embedding - Data type: object\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA INSPECTION ===\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows of each column:\")\n",
    "for col in ['text_stem', 'char_3grams', 'char_4grams', 'pos_tags', 'average_embedding']:\n",
    "    print(f\"\\n{col}:\")\n",
    "    if col == 'average_embedding':\n",
    "        print(f\"Type: {type(df[col].iloc[0])}\")\n",
    "        print(f\"Sample value: {df[col].iloc[0]}\")\n",
    "    else:\n",
    "        print(df[col].iloc[0][:100])  # Print first 100 chars\n",
    "        print(f\"Type: {type(df[col].iloc[0])}\")\n",
    "    print(f\"Has NaN: {df[col].isna().sum()}\")\n",
    "    \n",
    "print(\"\\n=== EMPTY STRING CHECK ===\")\n",
    "for col in ['text_stem', 'char_3grams', 'char_4grams', 'pos_tags']:\n",
    "    empty_count = (df[col].str.strip() == '').sum()\n",
    "    print(f\"{col} - Empty strings: {empty_count}\")\n",
    "\n",
    "print(\"\\n=== AVERAGE EMBEDDING CHECK ===\")\n",
    "print(f\"average_embedding - NaN values: {df['average_embedding'].isna().sum()}\")\n",
    "print(f\"average_embedding - Data type: {df['average_embedding'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a362cb-9d8c-4e25-bfcf-bf8bdd19e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert average_embedding from string to numpy array if needed\n",
    "def parse_embedding(embed_str):\n",
    "    \"\"\"Convert string representation of embedding to numpy array\"\"\"\n",
    "    if pd.isna(embed_str) or embed_str == '':\n",
    "        return np.zeros(100) \n",
    "    try:\n",
    "        # Remove brackets and split by spaces/commas\n",
    "        embed_str = embed_str.strip('[]')\n",
    "        return np.array([float(x) for x in embed_str.split()])\n",
    "    except:\n",
    "        return np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3554ac8-1e6e-43f5-aa7e-d90144ca8eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting average_embedding from string to numpy arrays...\n",
      "Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "# Apply conversion if average_embedding is stored as string\n",
    "if df['average_embedding'].dtype == object:\n",
    "    print(\"Converting average_embedding from string to numpy arrays...\")\n",
    "    df['average_embedding'] = df['average_embedding'].apply(parse_embedding)\n",
    "    print(\"Conversion completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4171a783-77f0-44d1-9e96-30abae65cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace_tokenizer(text):\n",
    "    \"\"\"Simple tokenizer that splits on whitespace\"\"\"\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        return []\n",
    "    return str(text).split()\n",
    "\n",
    "def pipe_tokenizer(text):\n",
    "    \"\"\"Simple tokenizer that splits on the | character\"\"\"\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        return []\n",
    "    return str(text).split('|')\n",
    "\n",
    "def transform_embeddings(X):\n",
    "    \"\"\"Convert list of arrays to 2D array for embeddings\"\"\"\n",
    "    return np.vstack(X.values)\n",
    "\n",
    "\n",
    "embedding_transformer = FunctionTransformer(transform_embeddings)\n",
    "\n",
    "features = ['text_stem', 'char_3grams', 'char_4grams', 'pos_tags', 'average_embedding']\n",
    "\n",
    "X = df[features]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "def add_len_feats(X):\n",
    "    return X.assign(\n",
    "        txt_len=X['text_stem'].fillna('').str.len(),\n",
    "        word_cnt=X['text_stem'].fillna('').str.split().str.len()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d8c4ea-fe11-465f-9d3e-88d642dedbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = add_len_feats(X_train)\n",
    "X_test = add_len_feats(X_test)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # text_stem: Use whitespace_tokenizer and token_pattern=None\n",
    "        ('stem', TfidfVectorizer(\n",
    "            max_features=20000,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            strip_accents=None,\n",
    "            lowercase=False,\n",
    "            tokenizer=whitespace_tokenizer, \n",
    "            token_pattern=None             \n",
    "        ), 'text_stem'),\n",
    "        \n",
    "        # char_3grams: Pre-tokenized, just split on whitespace\n",
    "        ('tri', TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            tokenizer=whitespace_tokenizer,\n",
    "            token_pattern=None,\n",
    "            lowercase=False,\n",
    "            min_df=1\n",
    "        ), 'char_3grams'),\n",
    "        \n",
    "        # char_4grams: Pre-tokenized, just split on whitespace\n",
    "        ('four', TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            tokenizer=whitespace_tokenizer,\n",
    "            token_pattern=None,\n",
    "            lowercase=False,\n",
    "            min_df=1\n",
    "        ), 'char_4grams'),\n",
    "        \n",
    "        # pos_tags: Use pipe_tokenizer\n",
    "        ('pos', TfidfVectorizer(\n",
    "            max_features=8000,\n",
    "            tokenizer=pipe_tokenizer,       \n",
    "            token_pattern=None,\n",
    "            lowercase=False,\n",
    "            min_df=2\n",
    "        ), 'pos_tags'),\n",
    "        \n",
    "        # average_embedding: Use function transformer\n",
    "        ('embedding', embedding_transformer, 'average_embedding'),\n",
    "        \n",
    "        # Length features: Scale the numerical features\n",
    "        ('len_feats', StandardScaler(), ['txt_len', 'word_cnt'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257d7f3f-92d6-4f26-9cc5-efcca5a90597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TESTING PREPROCESSOR ===\n",
      "✓ Preprocessor works! Shape: (366, 16344)\n",
      "  Number of features: 16344\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TESTING PREPROCESSOR ===\")\n",
    "try:\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train, y_train)\n",
    "    print(f\"✓ Preprocessor works! Shape: {X_train_transformed.shape}\")\n",
    "    print(f\"  Number of features: {X_train_transformed.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Preprocessor failed: {e}\")\n",
    "    print(\"\\nTrying to identify which transformer failed...\")\n",
    "    \n",
    "    # Test each transformer individually\n",
    "    for name, transformer, columns in preprocessor.transformers:\n",
    "        try:\n",
    "            if isinstance(columns, str):\n",
    "                cols = [columns]\n",
    "            else:\n",
    "                cols = columns\n",
    "            \n",
    "            if name == 'embedding':\n",
    "                # Special handling for embedding column\n",
    "                result = transformer.fit_transform(X_train[cols])\n",
    "                print(f\"  ✓ {name} works - output shape: {result.shape}\")\n",
    "            else:\n",
    "                result = transformer.fit_transform(X_train[cols].fillna(''))\n",
    "                print(f\"  ✓ {name} works\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {name} failed: {e}\")\n",
    "            # Show sample data\n",
    "            print(f\"    Sample data: {X_train[cols].iloc[0].values}\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c60b7fc-db6e-4807-a532-5bd1a8b472f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LR': (\n",
    "        LogisticRegression(max_iter=1000, random_state=42),\n",
    "        {'model__C': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "    ),\n",
    "    'SVM': (\n",
    "        SVC(random_state=42),\n",
    "        {'model__C': [0.1, 1.0, 10.0], 'model__kernel': ['linear']}\n",
    "    ),\n",
    "    'KNN': (\n",
    "        KNeighborsClassifier(),\n",
    "        {'model__n_neighbors': [3,5,7],\n",
    "        'model__weights': ['uniform', 'distance']}\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19338212-62cc-4786-935b-2ce3f03fc908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training LR...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "LR Results:\n",
      "  Best CV Score: 0.7814\n",
      "  Best Parameters: {'model__C': 100.0}\n",
      "  Training Time: 2.68 seconds\n",
      "\n",
      "LR Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.61      0.66        51\n",
      "           1       0.75      0.83      0.79        72\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.74      0.72      0.72       123\n",
      "weighted avg       0.74      0.74      0.74       123\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training SVM...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "\n",
      "SVM Results:\n",
      "  Best CV Score: 0.7923\n",
      "  Best Parameters: {'model__C': 1.0, 'model__kernel': 'linear'}\n",
      "  Training Time: 2.46 seconds\n",
      "\n",
      "SVM Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65        51\n",
      "           1       0.75      0.82      0.78        72\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.73      0.71      0.72       123\n",
      "weighted avg       0.73      0.73      0.73       123\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training KNN...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      "KNN Results:\n",
      "  Best CV Score: 0.6339\n",
      "  Best Parameters: {'model__n_neighbors': 7, 'model__weights': 'uniform'}\n",
      "  Training Time: 0.65 seconds\n",
      "\n",
      "KNN Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.55      0.53        51\n",
      "           1       0.67      0.64      0.65        72\n",
      "\n",
      "    accuracy                           0.60       123\n",
      "   macro avg       0.59      0.59      0.59       123\n",
      "weighted avg       0.61      0.60      0.60       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_score = 0\n",
    "results = {}\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    pipe = Pipeline(steps=[\n",
    "        ('prep', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        clf = GridSearchCV(\n",
    "            pipe, params,\n",
    "            cv=3, \n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'best_score': clf.best_score_,\n",
    "            'best_params': clf.best_params_,\n",
    "            'training_time': end_time - start_time\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(f\"  Best CV Score: {clf.best_score_:.4f}\")\n",
    "        print(f\"  Best Parameters: {clf.best_params_}\")\n",
    "        print(f\"  Training Time: {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        # Test set evaluation\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(f\"\\n{name} Test Set Performance:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Track best model\n",
    "        if clf.best_score_ > best_score:\n",
    "            best_score = clf.best_score_\n",
    "            best_model = clf\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ {name} failed: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65dbcbd6-80bb-4cdf-835b-61a3669c8858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Best Model: SVM\n",
      "Best Parameters: {'model__C': 1.0, 'model__kernel': 'linear'}\n",
      "Best CV Score: 0.7923\n",
      "============================================================\n",
      "\n",
      "✓ Model saved as 'best_model.pkl'\n",
      "✓ Preprocessor saved as 'vectorizer.pkl'\n"
     ]
    }
   ],
   "source": [
    "if best_model is not None:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Best Model: {[k for k, v in results.items() if v['best_score'] == best_score][0]}\")\n",
    "    print(f\"Best Parameters: {best_model.best_params_}\")\n",
    "    print(f\"Best CV Score: {best_score:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Save model and preprocessor\n",
    "    joblib.dump(best_model, 'best_model.pkl')\n",
    "    joblib.dump(best_model.best_estimator_.named_steps['prep'], 'vectorizer.pkl')\n",
    "    \n",
    "    print(\"\\n✓ Model saved as 'best_model.pkl'\")\n",
    "    print(\"✓ Preprocessor saved as 'vectorizer.pkl'\")\n",
    "else:\n",
    "    print(\"\\n✗ No models trained successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
