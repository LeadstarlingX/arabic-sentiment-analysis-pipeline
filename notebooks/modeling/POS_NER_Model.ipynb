{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b397e4c-cf11-4d8a-a95e-98b6b2c91188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbd93ba-2d06-46e6-a4c5-d7a7c6c66080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('arabic_pos_ner_tagged.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94d7407-2161-4d4c-a837-165a500185cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 10,000\n",
      "Rows after filtering: 9,764\n",
      "Rows dropped: 236\n"
     ]
    }
   ],
   "source": [
    "MinimumArabicPercentage = 0.6\n",
    "\n",
    "original_count = len(df)\n",
    "\n",
    "df = df[df['arabic_ratio'] >= MinimumArabicPercentage]\n",
    "\n",
    "filtered_count = len(df)\n",
    "\n",
    "print(f\"Original rows: {original_count:,}\")\n",
    "print(f\"Rows after filtering: {filtered_count:,}\")\n",
    "print(f\"Rows dropped: {original_count - filtered_count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f27b00-ea6c-42fa-91da-c78a06a5d3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA INSPECTION ===\n",
      "Dataset shape: (9764, 7)\n",
      "\n",
      "First few rows of each column:\n",
      "\n",
      "text_stem:\n",
      "نعل ريح ردي هذه نعل كثر فهي دفي ريح سعر عقل لجد ريع زوج ونا علي حد سوا لدي زوج ونح نحب\n",
      "Type: <class 'str'>\n",
      "Has NaN: 0\n",
      "\n",
      "char_3grams:\n",
      "الن لنع نعا عال ال  ل ا  ال الم لمر مري ريح يحه حه  ه     ا  ار ارت رتد تدي دي  ي ه  هذ هذه ذه  ه ا \n",
      "Type: <class 'str'>\n",
      "Has NaN: 0\n",
      "\n",
      "char_4grams:\n",
      "النع لنعا نعال عال  ال ا ل ال  الم المر لمري مريح ريحه يحه  حه   ه  ا   ار  ارت ارتد رتدي تدي  دي ه \n",
      "Type: <class 'str'>\n",
      "Has NaN: 0\n",
      "\n",
      "pos_tagged:\n",
      "النعال_NOUN|المريحة_ADJ|:_PUNCT|أرتدي_VERB|هذه_DET|النعال_NOUN|كثيرً_ADJ|ا_PART|!_PUNCT|ف_CCONJ|هي_P\n",
      "Type: <class 'str'>\n",
      "Has NaN: 0\n",
      "\n",
      "=== EMPTY STRING CHECK ===\n",
      "text_stem - Empty strings: 0\n",
      "char_3grams - Empty strings: 0\n",
      "char_4grams - Empty strings: 0\n",
      "pos_tagged - Empty strings: 0\n",
      "ner_tagged - Empty strings: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA INSPECTION ===\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows of each column:\")\n",
    "for col in ['text_stem', 'char_3grams', 'char_4grams', 'pos_tagged']:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].iloc[0][:100])  # Print first 100 chars\n",
    "    print(f\"Type: {type(df[col].iloc[0])}\")\n",
    "    print(f\"Has NaN: {df[col].isna().sum()}\")\n",
    "    \n",
    "print(\"\\n=== EMPTY STRING CHECK ===\")\n",
    "for col in ['text_stem', 'char_3grams', 'char_4grams', 'pos_tagged', 'ner_tagged']:\n",
    "    empty_count = (df[col].str.strip() == '').sum()\n",
    "    print(f\"{col} - Empty strings: {empty_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ec9a3b-e2dd-4a5b-86a2-426771320220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace_tokenizer(text):\n",
    "    \"\"\"Simple tokenizer that splits on whitespace\"\"\"\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        return []\n",
    "    return str(text).split()\n",
    "\n",
    "def pipe_tokenizer(text):\n",
    "    \"\"\"Simple tokenizer that splits on the | character\"\"\"\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        return []\n",
    "    return str(text).split('|')\n",
    "\n",
    "df['ner_tagged'] = df['ner_tagged'].fillna('')\n",
    "\n",
    "features = ['text_stem', 'char_3grams', 'char_4grams', 'pos_tagged', 'ner_tagged']\n",
    "\n",
    "X = df[features]\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "def add_len_feats(X):\n",
    "    return X.assign(\n",
    "        txt_len=X['text_stem'].fillna('').str.len(),\n",
    "        word_cnt=X['text_stem'].fillna('').str.split().str.len()\n",
    "    )\n",
    "\n",
    "X_train = add_len_feats(X_train)\n",
    "X_test = add_len_feats(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab422ec3-d375-461d-a778-f04d35dd59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Best Model: LR\n",
    "#  Best CV Score: 0.8504\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # text_stem: Use whitespace_tokenizer and token_pattern=None\n",
    "        ('stem', TfidfVectorizer(\n",
    "            max_features=20000,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=2,\n",
    "            strip_accents=None,\n",
    "            lowercase=False,\n",
    "            tokenizer=whitespace_tokenizer, \n",
    "            token_pattern=None             \n",
    "        ), 'text_stem'),\n",
    "        \n",
    "        # char_3grams: Pre-tokenized, just split on whitespace\n",
    "        ('tri', TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            tokenizer=whitespace_tokenizer,\n",
    "            token_pattern=None,\n",
    "            lowercase=False,\n",
    "            min_df=1\n",
    "        ), 'char_3grams'),\n",
    "        \n",
    "        # char_4grams: Pre-tokenized, just split on whitespace\n",
    "        ('four', TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            tokenizer=whitespace_tokenizer,\n",
    "            token_pattern=None,\n",
    "            lowercase=False,\n",
    "            min_df=1\n",
    "        ), 'char_4grams'),\n",
    "        \n",
    "        # pos_tagged: Use pipe_tokenizer\n",
    "        ('pos', TfidfVectorizer(\n",
    "            max_features=8000,\n",
    "            tokenizer=pipe_tokenizer,       \n",
    "            token_pattern=None,\n",
    "            lowercase=False,\n",
    "            min_df=2\n",
    "        ), 'pos_tagged'),\n",
    "        ('ner', TfidfVectorizer(\n",
    "            max_features=5000,  # Entities are rarer, so 5k is a good start\n",
    "            tokenizer=pipe_tokenizer,       \n",
    "            token_pattern=None,\n",
    "            lowercase=False,\n",
    "            min_df=2  # Filter rare/noisy entities\n",
    "        ), 'ner_tagged'),\n",
    "        \n",
    "        # Length features: Scale the numerical features\n",
    "        ('len_feats', StandardScaler(), ['txt_len', 'word_cnt'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d9ff80-746a-48b4-84ca-2a279c3d5c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TESTING PREPROCESSOR ===\n",
      "✓ Preprocessor works! Shape: (7323, 39477)\n",
      "  Number of features: 39477\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TESTING PREPROCESSOR ===\")\n",
    "try:\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train, y_train)\n",
    "    print(f\"✓ Preprocessor works! Shape: {X_train_transformed.shape}\")\n",
    "    print(f\"  Number of features: {X_train_transformed.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Preprocessor failed: {e}\")\n",
    "    print(\"\\nTrying to identify which transformer failed...\")\n",
    "    \n",
    "    # Test each transformer individually\n",
    "    for name, transformer, columns in preprocessor.transformers:\n",
    "        if name == 'len_feats':\n",
    "            continue\n",
    "        try:\n",
    "            if isinstance(columns, str):\n",
    "                cols = [columns]\n",
    "            else:\n",
    "                cols = columns\n",
    "            transformer.fit_transform(X_train[cols].fillna(''))\n",
    "            print(f\"  ✓ {name} works\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ {name} failed: {e}\")\n",
    "            # Show sample data\n",
    "            print(f\"    Sample data: {X_train[cols].iloc[0].values}\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c006a1-3fff-4d80-a1d7-259e7921f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LR': (\n",
    "        LogisticRegression(max_iter=1000, random_state=42),\n",
    "        {'model__C': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "    ),\n",
    "    'SVM': (\n",
    "        SVC(random_state=42),\n",
    "        {'model__C': [0.1, 1.0, 10.0], 'model__kernel': ['linear']}\n",
    "    ),\n",
    "    'KNN': (\n",
    "        KNeighborsClassifier(),\n",
    "        {'model__n_neighbors': [3,5,7],\n",
    "         \n",
    "        'model__weights': ['uniform', 'distance']}\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6adfa764-62d8-4218-bfb6-5ea983e28381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training LR...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "\n",
      "LR Results:\n",
      "  Best CV Score: 0.8596\n",
      "  Best Parameters: {'model__C': 10.0}\n",
      "  Training Time: 15.95 seconds\n",
      "\n",
      "LR Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      1257\n",
      "           1       0.86      0.85      0.86      1184\n",
      "\n",
      "    accuracy                           0.86      2441\n",
      "   macro avg       0.86      0.86      0.86      2441\n",
      "weighted avg       0.86      0.86      0.86      2441\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training SVM...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "\n",
      "SVM Results:\n",
      "  Best CV Score: 0.8518\n",
      "  Best Parameters: {'model__C': 0.1, 'model__kernel': 'linear'}\n",
      "  Training Time: 319.85 seconds\n",
      "\n",
      "SVM Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1257\n",
      "           1       0.88      0.84      0.86      1184\n",
      "\n",
      "    accuracy                           0.87      2441\n",
      "   macro avg       0.87      0.86      0.87      2441\n",
      "weighted avg       0.87      0.87      0.87      2441\n",
      "\n",
      "\n",
      "============================================================\n",
      "Training KNN...\n",
      "============================================================\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      "KNN Results:\n",
      "  Best CV Score: 0.6816\n",
      "  Best Parameters: {'model__n_neighbors': 7, 'model__weights': 'distance'}\n",
      "  Training Time: 22.21 seconds\n",
      "\n",
      "KNN Test Set Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      1257\n",
      "           1       0.72      0.66      0.69      1184\n",
      "\n",
      "    accuracy                           0.71      2441\n",
      "   macro avg       0.71      0.71      0.71      2441\n",
      "weighted avg       0.71      0.71      0.71      2441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_score = 0\n",
    "results = {}\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    pipe = Pipeline(steps=[\n",
    "        ('prep', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        clf = GridSearchCV(\n",
    "            pipe, params,\n",
    "            cv=3, \n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'best_score': clf.best_score_,\n",
    "            'best_params': clf.best_params_,\n",
    "            'training_time': end_time - start_time\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(f\"  Best CV Score: {clf.best_score_:.4f}\")\n",
    "        print(f\"  Best Parameters: {clf.best_params_}\")\n",
    "        print(f\"  Training Time: {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        # Test set evaluation\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(f\"\\n{name} Test Set Performance:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Track best model\n",
    "        if clf.best_score_ > best_score:\n",
    "            best_score = clf.best_score_\n",
    "            best_model = clf\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ {name} failed: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "886b30db-0be3-43ca-b427-a38e5c5ae012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Best Model: LR\n",
      "Best Parameters: {'model__C': 10.0}\n",
      "Best CV Score: 0.8596\n",
      "============================================================\n",
      "\n",
      "✓ Model saved as 'best_model.pkl'\n",
      "✓ Preprocessor saved as 'vectorizer.pkl'\n"
     ]
    }
   ],
   "source": [
    "if best_model is not None:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Best Model: {[k for k, v in results.items() if v['best_score'] == best_score][0]}\")\n",
    "    print(f\"Best Parameters: {best_model.best_params_}\")\n",
    "    print(f\"Best CV Score: {best_score:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Save model and preprocessor\n",
    "    joblib.dump(best_model, 'best_model.pkl')\n",
    "    joblib.dump(best_model.best_estimator_.named_steps['prep'], 'vectorizer.pkl')\n",
    "    \n",
    "    print(\"\\n✓ Model saved as 'best_model.pkl'\")\n",
    "    print(\"✓ Preprocessor saved as 'vectorizer.pkl'\")\n",
    "else:\n",
    "    print(\"\\n✗ No models trained successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
